{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2ed2a3d",
   "metadata": {},
   "source": [
    "# DunnHumby Recommender System "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e5cba0",
   "metadata": {},
   "source": [
    "Update February 2022 --\n",
    "\n",
    "In the process of eventually deploying an app to `Heroku`, I've come a long way in terms of organizing my ETL structures. I'm grateful for having spent time learning more about coding in Python. This class is far too expensive, computationally, to run on a remote server. \n",
    "\n",
    "That limitation has forced me to consider alternatives -- and structure my 'business outcomes' in a more readable way. I'm going to go back and create several spectra of class labels; and then compare modelling results for each, such that I can find the households most similar to one another in certain areas -- this process in the end may involve more market basket analysis; fpgrowth; and association rules analysis. I'm figuring it out, albeit slowly. \n",
    "\n",
    "In the end I hope to be able to provide several core recommendation tables; for each of 3-5 class labels for households in the data. Moreover; to be able to generate those class labels using new data that might become available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab9e0e9",
   "metadata": {},
   "source": [
    "Because of the complexity of this dataset, and my weak background in statistics, I opted to showcase a Python class structure capable of generating recommendations for any given household based on their previous purchases. \n",
    "\n",
    "My thinking is that a system like this would be able to effectively identify profitable spending patterns by a household -- those associated products which influence the customer to spend more or purchase more frequently. \n",
    "\n",
    "For example, if our competitor pricing research found that we should target a specific product in order to vie for market share; **the recommender system below would be able to identify what other products might do well alongside the 'targeted' item in a marketing campaign to that customer. With multiple reasons to come to the store, the customer might be more inclined to make the trip, or to spend more if they do**. \n",
    "\n",
    "I recognize that in a brick-and-mortar store, having live-updating recommendations based on items in basket is not necessarily as useful as it would be in an online shop -- however, I believe there is value to be offered by using a system like this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575e4e70",
   "metadata": {},
   "source": [
    "Data Pipeline\n",
    "---\n",
    "\n",
    "The concept (and practice!) of molding data into a 'pipeline' is a deep one -- the 'correct answer' has to be negotiated based on current data infrastructure, available resources and future scope.\n",
    "\n",
    "An effective data pipeline would:\n",
    "\n",
    "- generate or otherwise acquire data\n",
    "- ensure the data's cleanliness and integrity\n",
    "- seamlessly add the data to an existing data pool\n",
    "- access that data as needed, for analysis and modelling\n",
    "- surface that analysis and modelling results\n",
    "\n",
    "For the scope of this project, we don't have much of a chance to acquire more data. But, if we assume that any other data would be in the same format as the data we've already received (big leap), then we've already made some work on creating a pipeline for future data.\n",
    "\n",
    "**pipeline thus far**:\n",
    "- commodity breakdown/sales analysis\n",
    "- adding datetime\n",
    "- data truncation\n",
    "- customer segmentation (RFM score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0a01d7",
   "metadata": {},
   "source": [
    "The pipeline is important, as it allows us to quickly identify changing patterns in customer purchase behaviour in the case of live or newly acquired data in the same format.\n",
    "\n",
    "Adding datetime is a 'housekeeping' issue which makes things easier on our end. \n",
    "\n",
    "Customer segmentation, however, provides some valuable insight about any given customer (household) in our data. \n",
    "\n",
    "By segmenting the customers in various ways, we can create effective recommendations for a given subset of our customers -- for example, the most profitable ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86e8c98f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\polan\\Desktop\\GitHub Repos\\DTCJ\\2.0 -- RecommenderSystem class.ipynb Cell 6\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/polan/Desktop/GitHub%20Repos/DTCJ/2.0%20--%20RecommenderSystem%20class.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m plt\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39mfigure.figsize\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m (\u001b[39m16\u001b[39m,\u001b[39m6\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/polan/Desktop/GitHub%20Repos/DTCJ/2.0%20--%20RecommenderSystem%20class.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdatetime\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/polan/Desktop/GitHub%20Repos/DTCJ/2.0%20--%20RecommenderSystem%20class.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmlxtend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m TransactionEncoder\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/polan/Desktop/GitHub%20Repos/DTCJ/2.0%20--%20RecommenderSystem%20class.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmlxtend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfrequent_patterns\u001b[39;00m \u001b[39mimport\u001b[39;00m apriori\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/polan/Desktop/GitHub%20Repos/DTCJ/2.0%20--%20RecommenderSystem%20class.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmlxtend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfrequent_patterns\u001b[39;00m \u001b[39mimport\u001b[39;00m association_rules\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (16,6)\n",
    "import datetime\n",
    "\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "\n",
    "import dtcj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662cbf35",
   "metadata": {},
   "source": [
    "Forming `merged` from `product.csv` and `transaction_data.csv`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e468b9",
   "metadata": {},
   "source": [
    "# Recommender System for Households\n",
    "---\n",
    "\n",
    "Using FPGrowth (apriori and association rules)\n",
    "\n",
    "Below I've implemented a rudimentary (minimum viable product?) Recommender System class.\n",
    "\n",
    "There is so much left for me to learn about how a class like this might be integrated into 'production'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b0bd77",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (16,6)\n",
    "import datetime\n",
    "\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "\n",
    "import dtcj\n",
    "\n",
    "class RecommenderSystem:\n",
    "    '''\n",
    "    ## hh_key :  the household_key\n",
    "    ## df : the transactions df; \n",
    "    ## column : the column in df to be used for MBA ('COMMODITY_DESC, DEPARTMENT, SUB_COMMODITY_DESC')\n",
    "    ## max_len :  max length of any antecedent/consequent chains in support_table\n",
    "    ## support_threshold : minimum 'support' threshold to generate fpgrowth\n",
    "    \n",
    "    ## metric : the association rules metric to maximize\n",
    "    ## assoc_threshold : the association rules threshold, given the metric.\n",
    "    '''\n",
    "        ## Instantiate Class\n",
    "\n",
    "    def __init__(self, \n",
    "                 hh_key,   ### FOR HOUSEHOLDS#!### \n",
    "                 df=merged, \n",
    "                 column='COMMODITY_DESC', \n",
    "                    max_len=None, ### CONSIDER REDUCING THIS VALUE FOR SIMPLICITY ###\n",
    "                 support_threshold=0.05, ### WITH DATA OF FIXED SIZE, NOT A CONCERN? ###\n",
    "                metric='confidence', \n",
    "                 assoc_threshold=0.8,\n",
    "                ):\n",
    "                                    #TODO: implement intelligent thresholds\n",
    "        self.hh = hh_key\n",
    "        self.metric = metric\n",
    "        self.assoc_threshold=assoc_threshold\n",
    "        self.column = column\n",
    "        self.support_threshold = support_threshold\n",
    "        self.df = df[df['household_key'] == self.hh] # self.df is transactions for this customer only\n",
    "        self.max_len = max_len\n",
    "        self.product_lists = []\n",
    "\n",
    "        # create support table upon instantiation\n",
    "        \n",
    "        self.get_support_table()\n",
    "     \n",
    "    \n",
    "    ### Support Table Function ###\n",
    "    # uses fpgrowth to generate a support table\n",
    "    def get_support_table(self):\n",
    "        '''Return the support table for `BASKET_ID`s using `column` as product lists\n",
    "        Note: 'BASKET_ID' is hardcoded...\n",
    "        \n",
    "        '''\n",
    "        # create product lists for each basket                                   \n",
    "        self.product_lists = self.df.groupby('BASKET_ID')[self.column].apply(list) # apply list constructor\n",
    " \n",
    "        # dummy encoding...\n",
    "        te = TransactionEncoder()\n",
    "        te_fit = te.fit_transform(self.product_lists.values, sparse=True) # encode each \n",
    "        te_df = pd.DataFrame.sparse.from_spmatrix(te_fit, columns=[str(i) for i in te.columns_])\n",
    "      \n",
    "        # fpgrowth table\n",
    "        frequent_itemsets = fpgrowth(te_df, \n",
    "                                    min_support=self.support_threshold, #can alter self.support_threshold\n",
    "                                    use_colnames=True, \n",
    "#                                     verbose=True, \n",
    "                                    max_len=self.max_len,   # can alter self.max_len here.\n",
    "                                    #, low_memory=True,                                   \n",
    "                                    )\n",
    "        # adding a length column for posterity and filtering\n",
    "        frequent_itemsets['size'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "        \n",
    "        # save variable for reference...\n",
    "        self.support_table = frequent_itemsets\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def assoc_table(self):\n",
    "        '''change self.metric, self.assoc_threshold to rank differently'''\n",
    "        ##  calling association rules on our support table\n",
    "        rules = association_rules(self.support_table, metric=self.metric, min_threshold=self.assoc_threshold)\n",
    "        rules[\"antecedent_len\"] = rules[\"antecedents\"].apply(lambda x: len(x))\n",
    "        return rules\n",
    "    \n",
    "    def recommend(self, prev_purchases:list, howmany=5):\n",
    "        '''meat and bones of the recommender system...\n",
    "        accepts:\n",
    "            prev_purchases: a list of previously purchased items\n",
    "            howmany: (int) how many recommendations you want\n",
    "            \n",
    "        returns:\n",
    "            a series consisting of the top 5 results given the self.metric value.\n",
    "            '''\n",
    "        search_terms = list(prev_purchases) # handles frozensets?\n",
    "        # apply list to 'antecedent' in self.assoc_table\n",
    "        search_series = pd.Series(self.assoc_table['antecedents'].apply(list)) \n",
    "        \n",
    "        print(f'Searching for {search_terms}...')\n",
    "        indexes_of_matches = []\n",
    "\n",
    "        # for each antecedent chain...\n",
    "        for item in search_terms:\n",
    "            # iterate through the list of \"antecedent\" rows **search_series**\n",
    "            for idx, val in search_series.iteritems():\n",
    "                if item in val: # if the item is in the row (list of antecedents)..\n",
    "                    indexes_of_matches.append(idx)\n",
    "\n",
    "        rules = self.assoc_table.loc[indexes_of_matches]\n",
    "\n",
    "\n",
    "        # RETURN TOP 5 LIFT CONSEQUENTS\n",
    "        return rules.sort_values(self.metric, ascending=False)[:howmany]['consequents']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7a2375",
   "metadata": {},
   "source": [
    "# Looping Recommendations to form new Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e640673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da155436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3d4b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = dtcj.load_merged()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d60c44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (16,6)\n",
    "import datetime\n",
    "\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "\n",
    "import dtcj\n",
    "\n",
    "\n",
    "class NewRecommenderSystem:\n",
    "    '''\n",
    "    ## hh_key :  the household_key\n",
    "    ## df : the transactions df; \n",
    "    ## column : the column in df to be used for MBA ('COMMODITY_DESC, DEPARTMENT, SUB_COMMODITY_DESC')\n",
    "    ## max_len :  max length of any antecedent/consequent chains in support_table\n",
    "    ## support_threshold : minimum 'support' threshold to generate fpgrowth\n",
    "    \n",
    "    ## metric : the association rules metric to maximize\n",
    "    ## assoc_threshold : the association rules threshold, given the metric.\n",
    "\n",
    "\n",
    "    \n",
    "        TODO: \n",
    "        Move chosen metric to the 'recommendation' function; \n",
    "            - allow for recommendations based on the 'strength' of the given metric against the overall mean and the metric's other values; as well as across other metrics?\n",
    "              \n",
    "                  '''\n",
    "        ## Instantiate Class\n",
    "\n",
    "    def __init__(self, \n",
    "                 hh_key,   ### FOR HOUSEHOLDS#!### \n",
    "                 df, \n",
    "                 column='COMMODITY_DESC', \n",
    "                    max_len=None, ### CONSIDER REDUCING THIS VALUE FOR SIMPLICITY ###\n",
    "                 support_threshold=0.05, ### WITH DATA OF FIXED SIZE, NOT A CONCERN? ###\n",
    "                metric='confidence', \n",
    "                 assoc_threshold=0.8,\n",
    "                ):\n",
    "                                    #TODO: implement intelligent thresholds\n",
    "        self.hh = hh_key\n",
    "        self.metric = metric\n",
    "        self.assoc_threshold=assoc_threshold\n",
    "        self.column = column\n",
    "        self.support_threshold = support_threshold\n",
    "        self.df = df[df['household_key'] == self.hh] # self.df is transactions for this customer only\n",
    "        self.max_len = max_len\n",
    "        self.product_lists = []\n",
    "\n",
    "        # create support table upon instantiation\n",
    "        \n",
    "        self.get_support_table()\n",
    "     \n",
    "    \n",
    "    ### Support Table Function ###\n",
    "    def get_support_table(self):\n",
    "        '''Return the support table for all `BASKET_ID`s using `column` as product lists...?\n",
    "        This should use the support table for only the individual's purchases, no?\n",
    "        Note: 'BASKET_ID' is hardcoded...\n",
    "        \n",
    "        '''\n",
    "\n",
    "        # create product lists for each basket   \n",
    "        self.product_lists = self.df[self.df['household_key'] == self.hh].groupby('BASKET_ID')[self.column].apply(list) \n",
    "\n",
    "        # dummy encoding...\n",
    "        te = TransactionEncoder()\n",
    "        te_fit = te.fit_transform(self.product_lists.values, sparse=True) # encode each \n",
    "        te_df = pd.DataFrame.sparse.from_spmatrix(te_fit, columns=[str(i) for i in te.columns_])\n",
    "      \n",
    "        # fpgrowth table\n",
    "        frequent_itemsets = fpgrowth(te_df, \n",
    "                                    min_support=self.support_threshold, #can alter self.support_threshold\n",
    "                                    use_colnames=True, \n",
    "#                                     verbose=True, \n",
    "                                    max_len=self.max_len,   # can alter self.max_len here.\n",
    "                                    #, low_memory=True,                                   \n",
    "                                    )\n",
    "        # adding a length column for posterity and filtering\n",
    "        frequent_itemsets['size'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "        \n",
    "        # save variable for reference...\n",
    "        self.support_table = frequent_itemsets\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def assoc_table(self):\n",
    "        '''change self.metric, self.assoc_threshold to rank differently'''\n",
    "        ##  calling association rules on our support table\n",
    "        rules = association_rules(self.support_table, metric=self.metric, min_threshold=self.assoc_threshold)\n",
    "        rules[\"antecedent_len\"] = rules[\"antecedents\"].apply(lambda x: len(x))\n",
    "        return rules\n",
    "    \n",
    "    def recommend(self, prev_purchases:list, howmany=5):\n",
    "        '''meat and bones of the recommender system...\n",
    "        accepts:\n",
    "            prev_purchases: a list of previously purchased items\n",
    "            howmany: (int) how many recommendations you want\n",
    "            \n",
    "        returns:\n",
    "            a series consisting of the top 5 results given the self.metric value.\n",
    "            '''\n",
    "        search_terms = list(prev_purchases) # handles frozensets?\n",
    "        # apply list to 'antecedent' in self.assoc_table\n",
    "        search_series = pd.Series(self.assoc_table['antecedents'].apply(list)) \n",
    "        \n",
    "        print(f'Searching for {search_terms}...')\n",
    "        indexes_of_matches = []\n",
    "\n",
    "        # this generates the full table of recommendations, no matter how small 'howmany' is.... crazy\n",
    "\n",
    "        # for each antecedent chain...\n",
    "        for item in search_terms:\n",
    "            # iterate through the list of \"antecedent\" rows **search_series**\n",
    "            for idx, val in search_series.iteritems():\n",
    "                if item in val: # if the item is in the row (list of antecedents)..\n",
    "                    indexes_of_matches.append(idx)\n",
    "\n",
    "        rules = self.assoc_table.loc[indexes_of_matches]\n",
    "\n",
    "\n",
    "        # RETURN TOP 5 LIFT CONSEQUENTS\n",
    "        return rules.sort_values(self.metric, ascending=False)[:howmany]['consequents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b093a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for ['CANDY - CHECKLANE', 'SOFT DRINKS', 'CANNED JUICES', 'SOUP', 'BAG SNACKS', 'BAKED SWEET GOODS', 'CRACKERS/MISC BKD FD', 'FLUID MILK PRODUCTS', 'BEEF', 'FROZEN PIZZA']...\n",
      "[frozenset({'CRACKERS/MISC BKD FD', 'BAKING MIXES'})\n",
      " frozenset({'BAKED SWEET GOODS', 'FLUID MILK PRODUCTS'})\n",
      " frozenset({'BAKED SWEET GOODS', 'FLUID MILK PRODUCTS'})\n",
      " frozenset({'REFRGRATD JUICES/DRNKS', 'CRACKERS/MISC BKD FD'})\n",
      " frozenset({'REFRGRATD JUICES/DRNKS', 'BAKED SWEET GOODS', 'CRACKERS/MISC BKD FD'})]\n",
      "Searching for ['FLUID MILK PRODUCTS', 'VEGETABLES - ALL OTHERS', 'WATER - CARBONATED/FLVRD DRINK', 'APPLES', 'TOMATOES', 'CRACKERS/MISC BKD FD', 'BREAD', 'BROCCOLI/CAULIFLOWER', 'COLD CEREAL', 'SQUASH']...\n",
      "[frozenset({'BROCCOLI/CAULIFLOWER'})\n",
      " frozenset({'PEARS', 'FLUID MILK PRODUCTS'}) frozenset({'PEARS'})\n",
      " frozenset({'PEARS'}) frozenset({'EGGS'})]\n",
      "Searching for ['CHEESE', 'BAKED BREAD/BUNS/ROLLS', 'SOFT DRINKS', 'LUNCHMEAT', 'FLUID MILK PRODUCTS', 'BEEF', 'CANDY - PACKAGED', 'BERRIES', 'FROZEN PIZZA', 'CONVENIENT BRKFST/WHLSM SNACKS']...\n",
      "[frozenset({'PASTA SAUCE'}) frozenset({'BEEF', 'DINNER SAUSAGE'})\n",
      " frozenset({'CHEESE', 'PASTA SAUCE'}) frozenset({'PASTA SAUCE'})\n",
      " frozenset({'PASTA SAUCE'})]\n",
      "Searching for ['FLUID MILK PRODUCTS', 'SOUP', 'GREETING CARDS/WRAP/PARTY SPLY', 'CHEESE', 'APPLES', 'BREAKFAST SWEETS', 'TROPICAL FRUIT', 'SALAD BAR', 'BAKED BREAD/BUNS/ROLLS', 'HISPANIC']...\n",
      "[frozenset({'MILK BY-PRODUCTS', 'BEEF'})\n",
      " frozenset({'HISPANIC', 'TOMATOES'})\n",
      " frozenset({'BEEF', 'MILK BY-PRODUCTS'})\n",
      " frozenset({'BEEF', 'CHEESE', 'MILK BY-PRODUCTS'})\n",
      " frozenset({'BEEF', 'MILK BY-PRODUCTS'})]\n"
     ]
    }
   ],
   "source": [
    "data = dict()\n",
    "# basic most-frequent heuristic\n",
    "# generate association rules based on the items most-frequently purchased\n",
    "\n",
    "for hh in merged['household_key'].unique()[:5]:\n",
    "    prev_purchases = merged[merged['household_key']==hh]['COMMODITY_DESC'].value_counts()[:10].keys()\n",
    "    #print(prev_purchases)\n",
    "    instance = NewRecommenderSystem(df=merged, hh_key=hh, metric='lift')\n",
    "    output = instance.recommend(prev_purchases=prev_purchases).values\n",
    "    print(output)\n",
    "\n",
    "    recommendations = list(frozenset().union(*output))\n",
    "    #print(recommendations)\n",
    "\n",
    "    data[hh] = recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62e4c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #print(prev_purchases)\n",
    "from collections import Counter\n",
    "Counter([len(x) for x in data.values()])\n",
    "# recommendations of equal length for each household\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b864c275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55                  (CANNED JUICES)\n",
       "546                          (BEEF)\n",
       "451          (CRACKERS/MISC BKD FD)\n",
       "453       (BAKED SWEET GOODS, BEEF)\n",
       "455    (CRACKERS/MISC BKD FD, BEEF)\n",
       "Name: consequents, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data[2319]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1824948e",
   "metadata": {},
   "source": [
    "May wish to look at alternative interpretations of the association_Rules table in the class, in order to generate recommendations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be20c59",
   "metadata": {},
   "source": [
    "## Demonstration\n",
    "---\n",
    "\n",
    "For `household_key == 2`, looking at 'confidence':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c457bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence\n",
      "Searching for ['APPLES']...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "174694                              (EGGS)\n",
       "179432    (BAKED BREAD/BUNS/ROLLS, YOGURT)\n",
       "179421                        (MARGARINES)\n",
       "179422            (BAKED BREAD/BUNS/ROLLS)\n",
       "179424                            (YOGURT)\n",
       "Name: consequents, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh2 = RecommenderSystem(hh_key=2, metric='confidence', assoc_threshold=0.8)#, max_len=2)\n",
    "\n",
    "print(hh2.metric)\n",
    "hh2.recommend(['APPLES'])\n",
    "# returns the top 5 'confidence' of all purchases with 'APPLES' antecedent for hh_key=2\n",
    "\n",
    "# these are the 5 products most often correlated with the purchase of 'APPLES'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c8d80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SOFT DRINKS                     48\n",
       "FLUID MILK PRODUCTS             28\n",
       "BAKED BREAD/BUNS/ROLLS          22\n",
       "BAKING MIXES                    19\n",
       "DOG FOODS                       17\n",
       "                                ..\n",
       "HOT CEREAL                       1\n",
       "FRZN MEAT/MEAT DINNERS           1\n",
       "BREAKFAST SAUSAGE/SANDWICHES     1\n",
       "FIRST AID PRODUCTS               1\n",
       "CANDY - PACKAGED                 1\n",
       "Name: COMMODITY_DESC, Length: 140, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh2.df['COMMODITY_DESC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596005f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hh2.product_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5af54c4",
   "metadata": {},
   "source": [
    "Looking at 'lift'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7895a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lift\n",
      "Searching for ['APPLES']...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "556                  (YOGURT)\n",
       "513    (FRUIT - SHELF STABLE)\n",
       "483    (CRACKERS/MISC BKD FD)\n",
       "349              (MARGARINES)\n",
       "264              (BAG SNACKS)\n",
       "Name: consequents, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh2 = RecommenderSystem(hh_key=2, metric='lift', assoc_threshold=0.8, max_len=2)\n",
    "print(hh2.metric)\n",
    "hh2.recommend(['APPLES'])\n",
    "# returns the top 5 'lift' of all purchases with 'APPLES' antecedent.\n",
    "# when the customer is purchasing apples, these products are often purchased (when they might not have been otherwise) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371dcf2a",
   "metadata": {},
   "source": [
    "Looking at 'conviction':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7099e8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for ['APPLES']...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "243       (FLUID MILK PRODUCTS)\n",
       "249               (SOFT DRINKS)\n",
       "250    (BAKED BREAD/BUNS/ROLLS)\n",
       "264                (BAG SNACKS)\n",
       "267         (BAKED SWEET GOODS)\n",
       "Name: consequents, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh2.metric='conviction'\n",
    "hh2.recommend(['APPLES']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97af212",
   "metadata": {},
   "source": [
    "Interpretation\n",
    "---\n",
    "\n",
    "For multi-item antecedent chains (items in 'basket'), this recommender searches for recommendations for each item independently, then concatenates the full table of results and sorts by the metric currently selected in the class .metric attribute.\n",
    "\n",
    "So many things to consider, with a technology like this. Does it make sense to filter more stringently, and only look for chains of antecedents precisely equal to the search term? What about finding similar products using something like word2vec or other NLP? How do we change or vary our recommendations, so that customers aren't constantly seeing the same recommendations?\n",
    "\n",
    "We could use cluster labels, RFM score, demographics to populate a 'similar customer' association rules table, and make recommendations from there. A basic approach would be to recommend based on recently purchased items; or to reverse-engineer this process and recommend 'trigger' products which we might want to be selling to them.\n",
    "\n",
    "We're getting redundant values in our consequent chains when parsing 5 straight from the top of the `confidence` metric. What about returning the results from a blend of metrics; another option would be to add another layer of logic to prevent redundant recommendations. (create a 'set', and don't stop filling it until it reaches 5 items). \n",
    "\n",
    "One issue about having an antecedent 'chain' instead of a single result: the recommendations won't always be obviously related. This could be frustrating for a customer. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab72cbad",
   "metadata": {},
   "source": [
    "Run the recommender on all of the purchases by a household using the support table of similarly-labeled customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8649d636",
   "metadata": {},
   "source": [
    "Alternative Methods of Recommendation\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f262174",
   "metadata": {},
   "source": [
    "- Instead of using the fpgrowth table for each household proper; use the Cluster label (or RFM score group) to generate a 'similar-customers' fpgrowth table; call .recommend() using that table, for the most recent purchases by the household.\n",
    "\n",
    "- Search a customer's history to see their 'DEPARTMENT' or 'COMMODITY' spending vs the average? \n",
    "\n",
    "- Get the rows for each top ranked value in a given support table.. #TODO: deal with ties, inf \n",
    "\n",
    "- Use NLP or regex to find similar items and make the search terms more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d4678b",
   "metadata": {},
   "source": [
    "## Second Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4bca1a",
   "metadata": {},
   "source": [
    "Expanding on the functionality\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1e79e6",
   "metadata": {},
   "source": [
    "By altering the last few lines of the recommend() function, we could instead return a `set` of items from the top of our results; or add several recommender metrics together and return the set of all items. for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30f4a08",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class RecommenderSystemSET:\n",
    "    '''\n",
    "    ## hh_key :  the household_key\n",
    "    ## df : the transactions df; \n",
    "    ## column : the column in df to be used for MBA ('COMMODITY_DESC, DEPARTMENT, SUB_COMMODITY_DESC')\n",
    "    ## max_len :  max length of any antecedent/consequent chains in support_table\n",
    "    ## support_threshold : minimum 'support' threshold to generate fpgrowth\n",
    "    \n",
    "    ## metric : the association rules metric to maximize\n",
    "    ## assoc_threshold : the association rules threshold, given the metric.\n",
    "    '''\n",
    "        ## Instantiate Class\n",
    "\n",
    "    def __init__(self, \n",
    "                 hh_key,   ### FOR HOUSEHOLDS#!### \n",
    "                 df=merged, \n",
    "                 column='COMMODITY_DESC', \n",
    "                    max_len=None, ### CONSIDER REDUCING THIS VALUE FOR SIMPLICITY ###\n",
    "                 support_threshold=0.05, ### WITH DATA OF FIXED SIZE, NOT A CONCERN? ###\n",
    "                metric='confidence', \n",
    "                 assoc_threshold=0.8,\n",
    "                ):\n",
    "                                    #TODO: implement intelligent thresholds\n",
    "        self.hh = hh_key\n",
    "        self.metric = metric\n",
    "        self.assoc_threshold=assoc_threshold\n",
    "        self.column = column\n",
    "        self.support_threshold = support_threshold\n",
    "        self.df = df[df['household_key'] == self.hh] # self.df is transactions for this customer only\n",
    "        self.max_len = max_len\n",
    "        self.product_lists = []\n",
    "\n",
    "        # create support table upon instantiation\n",
    "        \n",
    "        self.get_support_table()\n",
    "     \n",
    "    \n",
    "    ### Support Table Function ###\n",
    "    \n",
    "    # uses fpgrowth to generate a support table\n",
    "    \n",
    "    def get_support_table(self):\n",
    "        '''Return the support table for `BASKET_ID`s using `column` as product lists\n",
    "        Note: 'BASKET_ID' is hardcoded...\n",
    "        \n",
    "        '''\n",
    "        # create product lists for each basket                                   \n",
    "        self.product_lists = self.df.groupby('BASKET_ID')[self.column].apply(list) # apply list constructor\n",
    " \n",
    "        # dummy encoding...\n",
    "        te = TransactionEncoder()\n",
    "        te_fit = te.fit_transform(self.product_lists.values, sparse=True) # encode each \n",
    "        te_df = pd.DataFrame.sparse.from_spmatrix(te_fit, columns=[str(i) for i in te.columns_])\n",
    "      \n",
    "        # fpgrowth table\n",
    "        frequent_itemsets = fpgrowth(te_df, \n",
    "                                    min_support=self.support_threshold, #can alter self.support_threshold\n",
    "                                    use_colnames=True, \n",
    "#                                     verbose=True, \n",
    "                                    max_len=self.max_len,   # can alter self.max_len here.\n",
    "                                    #, low_memory=True,                                   \n",
    "                                    )\n",
    "        # adding a length column for posterity and filtering\n",
    "        frequent_itemsets['size'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "        \n",
    "        # save variable for reference...\n",
    "        self.support_table = frequent_itemsets\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def assoc_table(self):\n",
    "        '''change self.metric, self.assoc_threshold to rank differently'''\n",
    "        ##  calling association rules on our support table\n",
    "        rules = association_rules(self.support_table, metric=self.metric, min_threshold=self.assoc_threshold)\n",
    "        rules[\"antecedent_len\"] = rules[\"antecedents\"].apply(lambda x: len(x))\n",
    "        return rules\n",
    "    \n",
    "    \n",
    "    def recommend(self, prev_purchases:list, howmany=5):\n",
    "        '''Edited Function\n",
    "            '''\n",
    "\n",
    "        search_terms = list(prev_purchases) # handles frozensets?\n",
    "        # apply list to 'antecedent' in self.assoc_table\n",
    "        search_series = pd.Series(self.assoc_table['antecedents'].apply(list)) \n",
    "\n",
    "        print(f'Searching for {search_terms}...')\n",
    "        indexes_of_matches = []\n",
    "\n",
    "        # for each antecedent chain...\n",
    "        for item in search_terms:\n",
    "            # iterate through the list of \"antecedent\" rows **search_series**\n",
    "            for idx, val in search_series.iteritems():\n",
    "                if item in val: # if the item is in the row (list of antecedents)..\n",
    "                    indexes_of_matches.append(idx)\n",
    "\n",
    "        rules = self.assoc_table.loc[indexes_of_matches]\n",
    "\n",
    "        # RETURN TOP 5 LIFT CONSEQUENTS\n",
    "        results = []\n",
    "        \n",
    "        \n",
    "        # TODO: check if the tables are populating correctly given only self.metric...\n",
    "        for metric in ['confidence', 'conviction', 'lift', 'leverage', 'support']:\n",
    "            results.extend(list(rules.sort_values(metric, ascending=False)[:howmany]['consequents']))\n",
    "\n",
    "        set_results = []\n",
    "        for x in results:\n",
    "            set_results.extend(list(x))\n",
    "        #       \n",
    "        return set(set_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00b8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh2 = RecommenderSystemSET(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63925307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADULT INCONTINENCE',\n",
       " 'AIR CARE',\n",
       " 'ANALGESICS',\n",
       " 'APPLES',\n",
       " 'BABY FOODS',\n",
       " 'BACON',\n",
       " 'BAG SNACKS',\n",
       " 'BAKED BREAD/BUNS/ROLLS',\n",
       " 'BAKED SWEET GOODS',\n",
       " 'BAKING',\n",
       " 'BAKING MIXES',\n",
       " 'BAKING NEEDS',\n",
       " 'BATH',\n",
       " 'BATH TISSUES',\n",
       " 'BATTERIES',\n",
       " 'BEEF',\n",
       " 'BEERS/ALES',\n",
       " 'BERRIES',\n",
       " 'BLEACH',\n",
       " 'BREAD',\n",
       " 'BREAKFAST SAUSAGE/SANDWICHES',\n",
       " 'BREAKFAST SWEETS',\n",
       " 'BROCCOLI/CAULIFLOWER',\n",
       " 'BROOMS AND MOPS',\n",
       " 'CANDY - CHECKLANE',\n",
       " 'CANDY - PACKAGED',\n",
       " 'CANNED JUICES',\n",
       " 'CARROTS',\n",
       " 'CHEESE',\n",
       " 'CHEESES',\n",
       " 'CHICKEN',\n",
       " 'CHRISTMAS  SEASONAL',\n",
       " 'CIGARETTES',\n",
       " 'CITRUS',\n",
       " 'COFFEE',\n",
       " 'COFFEE FILTERS',\n",
       " 'COLD CEREAL',\n",
       " 'CONDIMENTS/SAUCES',\n",
       " 'CONVENIENT BRKFST/WHLSM SNACKS',\n",
       " 'COOKIES/CONES',\n",
       " 'COOKWARE & BAKEWARE',\n",
       " 'CORN',\n",
       " 'COUPON/MISC ITEMS',\n",
       " 'CRACKERS/MISC BKD FD',\n",
       " 'DELI MEATS',\n",
       " 'DEODORANTS',\n",
       " 'DINNER MXS:DRY',\n",
       " 'DISHWASH DETERGENTS',\n",
       " 'DISPOSIBLE FOILWARE',\n",
       " 'DOG FOODS',\n",
       " 'DRIED FRUIT',\n",
       " 'DRY BN/VEG/POTATO/RICE',\n",
       " 'DRY MIX DESSERTS',\n",
       " 'DRY NOODLES/PASTA',\n",
       " 'EGGS',\n",
       " 'ELECTRICAL SUPPPLIES',\n",
       " 'FACIAL TISS/DNR NAPKIN',\n",
       " 'FAMILY PLANNING',\n",
       " 'FD WRAPS/BAGS/TRSH BG',\n",
       " 'FEMININE HYGIENE',\n",
       " 'FIRST AID PRODUCTS',\n",
       " 'FLORAL-FLOWERING PLANTS',\n",
       " 'FLOUR & MEALS',\n",
       " 'FLUID MILK PRODUCTS',\n",
       " 'FROZEN BREAD/DOUGH',\n",
       " 'FROZEN PIE/DESSERTS',\n",
       " 'FROZEN PIZZA',\n",
       " 'FRUIT - SHELF STABLE',\n",
       " 'FRZN BREAKFAST FOODS',\n",
       " 'FRZN FRUITS',\n",
       " 'FRZN MEAT/MEAT DINNERS',\n",
       " 'FRZN NOVELTIES/WTR ICE',\n",
       " 'FRZN VEGETABLE/VEG DSH',\n",
       " 'GRAPES',\n",
       " 'GREETING CARDS/WRAP/PARTY SPLY',\n",
       " 'HAIR CARE ACCESSORIES',\n",
       " 'HAIR CARE PRODUCTS',\n",
       " 'HAND/BODY/FACIAL PRODUCTS',\n",
       " 'HARDWARE SUPPLIES',\n",
       " 'HEAT/SERVE',\n",
       " 'HISPANIC',\n",
       " 'HOSIERY/SOCKS',\n",
       " 'HOT CEREAL',\n",
       " 'HOT DOGS',\n",
       " 'HOUSEHOLD CLEANG NEEDS',\n",
       " 'ICE CREAM/MILK/SHERBTS',\n",
       " 'LAUNDRY ADDITIVES',\n",
       " 'LAUNDRY DETERGENTS',\n",
       " 'LUNCHMEAT',\n",
       " 'MAKEUP AND TREATMENT',\n",
       " 'MARGARINES',\n",
       " 'MEAT - MISC',\n",
       " 'MILK BY-PRODUCTS',\n",
       " 'MISC. DAIRY',\n",
       " 'MOLASSES/SYRUP/PANCAKE MIXS',\n",
       " 'MUSHROOMS',\n",
       " 'OLIVES',\n",
       " 'ONIONS',\n",
       " 'ORAL HYGIENE PRODUCTS',\n",
       " 'ORGANICS FRUIT & VEGETABLES',\n",
       " 'PAPER HOUSEWARES',\n",
       " 'PAPER TOWELS',\n",
       " 'PASTA SAUCE',\n",
       " 'PET CARE SUPPLIES',\n",
       " 'PLASTIC HOUSEWARES',\n",
       " 'PNT BTR/JELLY/JAMS',\n",
       " 'PORK',\n",
       " 'POTATOES',\n",
       " 'PROCESSED',\n",
       " 'PWDR/CRYSTL DRNK MX',\n",
       " 'REFRGRATD DOUGH PRODUCTS',\n",
       " 'REFRGRATD JUICES/DRNKS',\n",
       " 'RICE CAKES',\n",
       " 'ROLLS',\n",
       " 'SALAD MIX',\n",
       " 'SALD DRSNG/SNDWCH SPRD',\n",
       " 'SEAFOOD - FROZEN',\n",
       " 'SEAFOOD - SHELF STABLE',\n",
       " 'SHAVING CARE PRODUCTS',\n",
       " 'SHORTENING/OIL',\n",
       " 'SOAP - LIQUID & BAR',\n",
       " 'SOFT DRINKS',\n",
       " 'SOUP',\n",
       " 'SPICES & EXTRACTS',\n",
       " 'SPRING/SUMMER SEASONAL',\n",
       " 'SQUASH',\n",
       " 'STATIONERY & SCHOOL SUPPLIES',\n",
       " 'STONE FRUIT',\n",
       " 'SUGARS/SWEETNERS',\n",
       " 'TEAS',\n",
       " 'TOBACCO OTHER',\n",
       " 'TOMATOES',\n",
       " 'TROPICAL FRUIT',\n",
       " 'VALUE ADDED FRUIT',\n",
       " 'VALUE ADDED VEGETABLES',\n",
       " 'VEGETABLES - ALL OTHERS',\n",
       " 'VEGETABLES - SHELF STABLE',\n",
       " 'WAREHOUSE SNACKS',\n",
       " 'WATER - CARBONATED/FLVRD DRINK',\n",
       " 'YOGURT'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(merged[merged['household_key']==2]['COMMODITY_DESC']) # all previous purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a5b113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most frequent????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525c5643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAPER HOUSEWARES',\n",
       " 'SOFT DRINKS',\n",
       " 'CANNED JUICES',\n",
       " 'BREAD',\n",
       " 'PET CARE SUPPLIES']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_recent = list(merged[merged['household_key']==2].sort_values('datetime')['COMMODITY_DESC'])[-5:]\n",
    "most_recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f2a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh2.metric = 'lift'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d3ff13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for ['PAPER HOUSEWARES', 'SOFT DRINKS', 'CANNED JUICES', 'BREAD', 'PET CARE SUPPLIES']...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BAKED BREAD/BUNS/ROLLS',\n",
       " 'BAKING MIXES',\n",
       " 'BAKING NEEDS',\n",
       " 'BEEF',\n",
       " 'CANNED JUICES',\n",
       " 'COOKIES/CONES',\n",
       " 'DEODORANTS',\n",
       " 'DOG FOODS',\n",
       " 'FLUID MILK PRODUCTS',\n",
       " 'PET CARE SUPPLIES',\n",
       " 'POTATOES',\n",
       " 'SHORTENING/OIL',\n",
       " 'SOFT DRINKS',\n",
       " 'SUGARS/SWEETNERS',\n",
       " 'VEGETABLES - SHELF STABLE',\n",
       " 'YOGURT'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh2.recommend(most_recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce7cfb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for ['BAKED BREAD/BUNS/ROLLS']...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BAKED SWEET GOODS',\n",
       " 'BAKING MIXES',\n",
       " 'BAKING NEEDS',\n",
       " 'BEEF',\n",
       " 'CANNED JUICES',\n",
       " 'COOKIES/CONES',\n",
       " 'FLUID MILK PRODUCTS',\n",
       " 'MARGARINES',\n",
       " 'ONIONS',\n",
       " 'PET CARE SUPPLIES',\n",
       " 'POTATOES',\n",
       " 'SOFT DRINKS',\n",
       " 'VEGETABLES - SHELF STABLE',\n",
       " 'YOGURT'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh2.recommend(['BAKED BREAD/BUNS/ROLLS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba99a32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>antecedent_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(SALADS/DIPS)</td>\n",
       "      <td>(BAG SNACKS)</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(BAG SNACKS)</td>\n",
       "      <td>(SALADS/DIPS)</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     antecedents    consequents  antecedent support  consequent support  \\\n",
       "0  (SALADS/DIPS)   (BAG SNACKS)            0.166667            0.166667   \n",
       "1   (BAG SNACKS)  (SALADS/DIPS)            0.166667            0.166667   \n",
       "\n",
       "    support  confidence  lift  leverage  conviction  antecedent_len  \n",
       "0  0.111111    0.666667   4.0  0.083333         2.5               1  \n",
       "1  0.111111    0.666667   4.0  0.083333         2.5               1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh5 = RecommenderSystem(hh_key=5, support_threshold=0.1) # consider opening this range further\n",
    "hh5.metric='confidence'\n",
    "hh5.assoc_threshold=0.2 # very low. \n",
    "\n",
    "hh5.assoc_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccad928",
   "metadata": {},
   "source": [
    "# Association Rules Metrics \n",
    "\n",
    "There is a ton of information that can be gathered by this sort of analysis;\n",
    "\n",
    "By calculating the 'frequency of occurrence' (`support`) for each item (in this case, `COMMODITY_DESC`) as such, we can then perform calculations to determine **if the presence of one product in the purchase basket** has affected the chance that **another product will be purchased** ; by how much (`lift` factor); and how strong the association is (`confidence` proportion).\n",
    "\n",
    "Below we can see some of the calculations quickly using the `association_rules` function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7718cf87",
   "metadata": {},
   "source": [
    "\n",
    "For example, one top-rated association in the `lift` category from the table above is [butter and pasta sauce] -> [dry noodles and cheese]. This means that the chance of having dry noodles AND cheese in your basket -- if you have butter AND pasta sauce *already* -- is increased by a factor of almost 16 times compared to the original `supports` of those chains of items independent of one another. \n",
    "\n",
    "If instead we sort the table by `confidence`, we can look at the proportion of co-occurence the `antecedent` (chain) exists on it's own.\n",
    "\n",
    "We create this table below using a threshold for the `confidence` metric; calculated as: how many baskets does the `consequent` appear in **with** the `antecedent`, divided by the total number of baskets in which the `antecedent` is present.\n",
    "\n",
    "A confidence score approaching 1 reflects that the `consequent` is found in the `antecedent`'s baskets\n",
    "approaching --> 100% of the time. \n",
    "\n",
    "Below we can see the highest-`confidence` relationships from the the purchases in our data, and the categories in `COMMODITY_DESC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da689e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>antecedent_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(BAKED BREAD/BUNS/ROLLS)</td>\n",
       "      <td>(SOFT DRINKS)</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>1.462500</td>\n",
       "      <td>0.091358</td>\n",
       "      <td>2.370370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(SOFT DRINKS, BAKED BREAD/BUNS/ROLLS)</td>\n",
       "      <td>(FLUID MILK PRODUCTS)</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.903846</td>\n",
       "      <td>0.116049</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(FLUID MILK PRODUCTS, BAKED BREAD/BUNS/ROLLS)</td>\n",
       "      <td>(SOFT DRINKS)</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>0.096296</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(TOMATOES)</td>\n",
       "      <td>(BAKED BREAD/BUNS/ROLLS)</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.812500</td>\n",
       "      <td>0.071605</td>\n",
       "      <td>inf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(SOFT DRINKS, TOMATOES)</td>\n",
       "      <td>(BAKED BREAD/BUNS/ROLLS)</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.812500</td>\n",
       "      <td>0.042963</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338935</th>\n",
       "      <td>(DRY NOODLES/PASTA, DOG FOODS)</td>\n",
       "      <td>(SOFT DRINKS, DEODORANTS, BAKED BREAD/BUNS/ROL...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338936</th>\n",
       "      <td>(PASTA SAUCE, DOG FOODS)</td>\n",
       "      <td>(SOFT DRINKS, DEODORANTS, BAKED BREAD/BUNS/ROL...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>0.060741</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338937</th>\n",
       "      <td>(DRY NOODLES/PASTA, PASTA SAUCE)</td>\n",
       "      <td>(SOFT DRINKS, DEODORANTS, BAKED BREAD/BUNS/ROL...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.059259</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338938</th>\n",
       "      <td>(FLUID MILK PRODUCTS, PASTA SAUCE)</td>\n",
       "      <td>(SOFT DRINKS, DEODORANTS, BAKED BREAD/BUNS/ROL...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338939</th>\n",
       "      <td>(PASTA SAUCE)</td>\n",
       "      <td>(SOFT DRINKS, DEODORANTS, BAKED BREAD/BUNS/ROL...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>inf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338940 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          antecedents  \\\n",
       "0                            (BAKED BREAD/BUNS/ROLLS)   \n",
       "1               (SOFT DRINKS, BAKED BREAD/BUNS/ROLLS)   \n",
       "2       (FLUID MILK PRODUCTS, BAKED BREAD/BUNS/ROLLS)   \n",
       "3                                          (TOMATOES)   \n",
       "4                             (SOFT DRINKS, TOMATOES)   \n",
       "...                                               ...   \n",
       "338935                 (DRY NOODLES/PASTA, DOG FOODS)   \n",
       "338936                       (PASTA SAUCE, DOG FOODS)   \n",
       "338937               (DRY NOODLES/PASTA, PASTA SAUCE)   \n",
       "338938             (FLUID MILK PRODUCTS, PASTA SAUCE)   \n",
       "338939                                  (PASTA SAUCE)   \n",
       "\n",
       "                                              consequents  antecedent support  \\\n",
       "0                                           (SOFT DRINKS)            0.355556   \n",
       "1                                   (FLUID MILK PRODUCTS)            0.288889   \n",
       "2                                           (SOFT DRINKS)            0.266667   \n",
       "3                                (BAKED BREAD/BUNS/ROLLS)            0.111111   \n",
       "4                                (BAKED BREAD/BUNS/ROLLS)            0.066667   \n",
       "...                                                   ...                 ...   \n",
       "338935  (SOFT DRINKS, DEODORANTS, BAKED BREAD/BUNS/ROL...            0.066667   \n",
       "338936  (SOFT DRINKS, DEODORANTS, BAKED BREAD/BUNS/ROL...            0.066667   \n",
       "338937  (SOFT DRINKS, DEODORANTS, BAKED BREAD/BUNS/ROL...            0.066667   \n",
       "338938  (SOFT DRINKS, DEODORANTS, BAKED BREAD/BUNS/ROL...            0.066667   \n",
       "338939  (SOFT DRINKS, DEODORANTS, BAKED BREAD/BUNS/ROL...            0.066667   \n",
       "\n",
       "        consequent support   support  confidence       lift  leverage  \\\n",
       "0                 0.555556  0.288889    0.812500   1.462500  0.091358   \n",
       "1                 0.444444  0.244444    0.846154   1.903846  0.116049   \n",
       "2                 0.555556  0.244444    0.916667   1.650000  0.096296   \n",
       "3                 0.355556  0.111111    1.000000   2.812500  0.071605   \n",
       "4                 0.355556  0.066667    1.000000   2.812500  0.042963   \n",
       "...                    ...       ...         ...        ...       ...   \n",
       "338935            0.066667  0.066667    1.000000  15.000000  0.062222   \n",
       "338936            0.088889  0.066667    1.000000  11.250000  0.060741   \n",
       "338937            0.111111  0.066667    1.000000   9.000000  0.059259   \n",
       "338938            0.066667  0.066667    1.000000  15.000000  0.062222   \n",
       "338939            0.066667  0.066667    1.000000  15.000000  0.062222   \n",
       "\n",
       "        conviction  antecedent_len  \n",
       "0         2.370370               1  \n",
       "1         3.611111               2  \n",
       "2         5.333333               2  \n",
       "3              inf               1  \n",
       "4              inf               2  \n",
       "...            ...             ...  \n",
       "338935         inf               2  \n",
       "338936         inf               2  \n",
       "338937         inf               2  \n",
       "338938         inf               2  \n",
       "338939         inf               1  \n",
       "\n",
       "[338940 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh2.assoc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79ab0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>(SOFT DRINKS)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.355556</td>\n",
       "      <td>(BAKED BREAD/BUNS/ROLLS)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>(TOMATOES)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>(STONE FRUIT)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>(MILK BY-PRODUCTS)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9726</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>(SOFT DRINKS, DEODORANTS, DOG FOODS, DRY NOODL...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9727</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>(SOFT DRINKS, DEODORANTS, BAKED BREAD/BUNS/ROL...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9728</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>(SOFT DRINKS, BAKED BREAD/BUNS/ROLLS, DOG FOOD...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9729</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>(SOFT DRINKS, DEODORANTS, BAKED BREAD/BUNS/ROL...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9730</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>(SOFT DRINKS, DEODORANTS, BAKED BREAD/BUNS/ROL...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9731 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       support                                           itemsets  size\n",
       "0     0.555556                                      (SOFT DRINKS)     1\n",
       "1     0.355556                           (BAKED BREAD/BUNS/ROLLS)     1\n",
       "2     0.111111                                         (TOMATOES)     1\n",
       "3     0.111111                                      (STONE FRUIT)     1\n",
       "4     0.111111                                 (MILK BY-PRODUCTS)     1\n",
       "...        ...                                                ...   ...\n",
       "9726  0.066667  (SOFT DRINKS, DEODORANTS, DOG FOODS, DRY NOODL...     6\n",
       "9727  0.066667  (SOFT DRINKS, DEODORANTS, BAKED BREAD/BUNS/ROL...     6\n",
       "9728  0.066667  (SOFT DRINKS, BAKED BREAD/BUNS/ROLLS, DOG FOOD...     6\n",
       "9729  0.066667  (SOFT DRINKS, DEODORANTS, BAKED BREAD/BUNS/ROL...     6\n",
       "9730  0.066667  (SOFT DRINKS, DEODORANTS, BAKED BREAD/BUNS/ROL...     7\n",
       "\n",
       "[9731 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh2.support_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b452b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>antecedent_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169470</th>\n",
       "      <td>(BAKING MIXES, SOFT DRINKS, BAKED BREAD/BUNS/R...</td>\n",
       "      <td>(VEGETABLES - SHELF STABLE, BEEF, BAKING NEEDS)</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.25</td>\n",
       "      <td>0.060741</td>\n",
       "      <td>inf</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225583</th>\n",
       "      <td>(BAKING MIXES, CANNED JUICES, FLUID MILK PRODU...</td>\n",
       "      <td>(BEEF, YOGURT, SOFT DRINKS, COOKIES/CONES, BAK...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>inf</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225581</th>\n",
       "      <td>(SOFT DRINKS, BAKING MIXES, CANNED JUICES)</td>\n",
       "      <td>(BEEF, YOGURT, COOKIES/CONES, FLUID MILK PRODU...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>inf</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225580</th>\n",
       "      <td>(BAKING MIXES, BAKING NEEDS, YOGURT)</td>\n",
       "      <td>(BEEF, SOFT DRINKS, COOKIES/CONES, CANNED JUIC...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>inf</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225579</th>\n",
       "      <td>(BAKING MIXES, FLUID MILK PRODUCTS, YOGURT)</td>\n",
       "      <td>(BEEF, SOFT DRINKS, COOKIES/CONES, CANNED JUIC...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>inf</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225578</th>\n",
       "      <td>(BAKING MIXES, CANNED JUICES, YOGURT)</td>\n",
       "      <td>(BEEF, SOFT DRINKS, COOKIES/CONES, FLUID MILK ...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.25</td>\n",
       "      <td>0.060741</td>\n",
       "      <td>inf</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225577</th>\n",
       "      <td>(COOKIES/CONES, BAKING MIXES, YOGURT)</td>\n",
       "      <td>(BEEF, SOFT DRINKS, CANNED JUICES, FLUID MILK ...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>inf</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225576</th>\n",
       "      <td>(SOFT DRINKS, BAKING MIXES, YOGURT)</td>\n",
       "      <td>(BEEF, COOKIES/CONES, CANNED JUICES, FLUID MIL...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>inf</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225575</th>\n",
       "      <td>(BAKING MIXES, CANNED JUICES, BEEF)</td>\n",
       "      <td>(YOGURT, SOFT DRINKS, COOKIES/CONES, FLUID MIL...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>inf</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225574</th>\n",
       "      <td>(BAKING MIXES, BEEF, YOGURT)</td>\n",
       "      <td>(SOFT DRINKS, COOKIES/CONES, CANNED JUICES, FL...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>inf</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225573</th>\n",
       "      <td>(CANNED JUICES, BAKING NEEDS, FLUID MILK PRODU...</td>\n",
       "      <td>(SOFT DRINKS, BAKING MIXES, BEEF, YOGURT)</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>inf</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225572</th>\n",
       "      <td>(SOFT DRINKS, CANNED JUICES, BAKING NEEDS, FLU...</td>\n",
       "      <td>(COOKIES/CONES, BAKING MIXES, BEEF, YOGURT)</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>inf</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              antecedents  \\\n",
       "169470  (BAKING MIXES, SOFT DRINKS, BAKED BREAD/BUNS/R...   \n",
       "225583  (BAKING MIXES, CANNED JUICES, FLUID MILK PRODU...   \n",
       "225581         (SOFT DRINKS, BAKING MIXES, CANNED JUICES)   \n",
       "225580               (BAKING MIXES, BAKING NEEDS, YOGURT)   \n",
       "225579        (BAKING MIXES, FLUID MILK PRODUCTS, YOGURT)   \n",
       "225578              (BAKING MIXES, CANNED JUICES, YOGURT)   \n",
       "225577              (COOKIES/CONES, BAKING MIXES, YOGURT)   \n",
       "225576                (SOFT DRINKS, BAKING MIXES, YOGURT)   \n",
       "225575                (BAKING MIXES, CANNED JUICES, BEEF)   \n",
       "225574                       (BAKING MIXES, BEEF, YOGURT)   \n",
       "225573  (CANNED JUICES, BAKING NEEDS, FLUID MILK PRODU...   \n",
       "225572  (SOFT DRINKS, CANNED JUICES, BAKING NEEDS, FLU...   \n",
       "\n",
       "                                              consequents  antecedent support  \\\n",
       "169470    (VEGETABLES - SHELF STABLE, BEEF, BAKING NEEDS)            0.066667   \n",
       "225583  (BEEF, YOGURT, SOFT DRINKS, COOKIES/CONES, BAK...            0.066667   \n",
       "225581  (BEEF, YOGURT, COOKIES/CONES, FLUID MILK PRODU...            0.066667   \n",
       "225580  (BEEF, SOFT DRINKS, COOKIES/CONES, CANNED JUIC...            0.066667   \n",
       "225579  (BEEF, SOFT DRINKS, COOKIES/CONES, CANNED JUIC...            0.066667   \n",
       "225578  (BEEF, SOFT DRINKS, COOKIES/CONES, FLUID MILK ...            0.066667   \n",
       "225577  (BEEF, SOFT DRINKS, CANNED JUICES, FLUID MILK ...            0.066667   \n",
       "225576  (BEEF, COOKIES/CONES, CANNED JUICES, FLUID MIL...            0.066667   \n",
       "225575  (YOGURT, SOFT DRINKS, COOKIES/CONES, FLUID MIL...            0.066667   \n",
       "225574  (SOFT DRINKS, COOKIES/CONES, CANNED JUICES, FL...            0.066667   \n",
       "225573          (SOFT DRINKS, BAKING MIXES, BEEF, YOGURT)            0.066667   \n",
       "225572        (COOKIES/CONES, BAKING MIXES, BEEF, YOGURT)            0.066667   \n",
       "\n",
       "        consequent support   support  confidence   lift  leverage  conviction  \\\n",
       "169470            0.088889  0.066667         1.0  11.25  0.060741         inf   \n",
       "225583            0.066667  0.066667         1.0  15.00  0.062222         inf   \n",
       "225581            0.066667  0.066667         1.0  15.00  0.062222         inf   \n",
       "225580            0.066667  0.066667         1.0  15.00  0.062222         inf   \n",
       "225579            0.066667  0.066667         1.0  15.00  0.062222         inf   \n",
       "225578            0.088889  0.066667         1.0  11.25  0.060741         inf   \n",
       "225577            0.066667  0.066667         1.0  15.00  0.062222         inf   \n",
       "225576            0.066667  0.066667         1.0  15.00  0.062222         inf   \n",
       "225575            0.066667  0.066667         1.0  15.00  0.062222         inf   \n",
       "225574            0.066667  0.066667         1.0  15.00  0.062222         inf   \n",
       "225573            0.066667  0.066667         1.0  15.00  0.062222         inf   \n",
       "225572            0.066667  0.066667         1.0  15.00  0.062222         inf   \n",
       "\n",
       "        antecedent_len  \n",
       "169470               6  \n",
       "225583               3  \n",
       "225581               3  \n",
       "225580               3  \n",
       "225579               3  \n",
       "225578               3  \n",
       "225577               3  \n",
       "225576               3  \n",
       "225575               3  \n",
       "225574               3  \n",
       "225573               4  \n",
       "225572               4  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh2 = RecommenderSystem(2)\n",
    "hh2.metric = 'confidence'\n",
    "hh2.assoc_table.sort_values(hh2.metric, ascending=False).head(12)\n",
    "#This table changes slightly without max_len=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebe07b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
